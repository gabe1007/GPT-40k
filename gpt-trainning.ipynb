{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T19:15:33.625050Z","iopub.status.busy":"2024-08-24T19:15:33.624459Z","iopub.status.idle":"2024-08-24T19:15:37.529104Z","shell.execute_reply":"2024-08-24T19:15:37.528092Z","shell.execute_reply.started":"2024-08-24T19:15:33.625018Z"},"trusted":true},"outputs":[],"source":["# Common imports \n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T19:15:59.157237Z","iopub.status.busy":"2024-08-24T19:15:59.156831Z","iopub.status.idle":"2024-08-24T19:16:00.540396Z","shell.execute_reply":"2024-08-24T19:16:00.539279Z","shell.execute_reply.started":"2024-08-24T19:15:59.157206Z"},"trusted":true},"outputs":[],"source":["BATCH_SIZE = 128 \n","BLOCK_SIZE = 256 \n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","N_EMBED = 192\n","N_HEADS = 3\n","DROPOUT = 0.2\n","N_LAYER = 4\n","LEARNING_RATE = 3e-3\n","MAX_ITERS = 10000\n","EVAL_INTERVAL = 500\n","EVAL_ITERS = 200\n","\n","# This notebook was last run in a Kaggle environment, so you must replace it\n","with open('./40k.txt', 'r', encoding='utf-8') as f:\n","    text = f.read()\n","\n","# Unique characters that occur in this text\n","chars = sorted(list(set(text)))\n","VOCAB_SIZE = len(chars)\n","\n","# Map the characters\n","stoi = { ch:i for i,ch in enumerate(chars) }\n","itos = { i:ch for i,ch in enumerate(chars) }\n","encode = lambda s: [stoi[c] for c in s]\n","decode = lambda l: ''.join([itos[i] for i in l]) \n","\n","# Get data splits\n","data = torch.tensor(encode(text), dtype=torch.long)\n","n = int(0.9*len(data)) \n","train = data[:n]\n","val = data[n:]"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T19:16:01.699517Z","iopub.status.busy":"2024-08-24T19:16:01.698939Z","iopub.status.idle":"2024-08-24T19:16:01.708061Z","shell.execute_reply":"2024-08-24T19:16:01.706912Z","shell.execute_reply.started":"2024-08-24T19:16:01.699465Z"},"trusted":true},"outputs":[],"source":["def get_batch(split, block_size=BLOCK_SIZE, batch_size=BATCH_SIZE):\n","    \"\"\"\n","    Get a batch of data for training or testing.\n","    \"\"\"\n","\n","    data = train if split == 'train' else val\n","    ix = torch.randint(len(data) - block_size, (batch_size,))\n","    x_batch = []\n","    y_batch = []\n","\n","    for i in ix:\n","        x_batch.append(data[i:i+block_size])\n","        y_batch.append(data[i+1:i+1+block_size])\n","\n","    x = torch.stack(x_batch)\n","    y = torch.stack(y_batch)\n","    x, y = x.to(DEVICE), y.to(DEVICE)\n","\n","    return x, y"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T19:16:03.140429Z","iopub.status.busy":"2024-08-24T19:16:03.140023Z","iopub.status.idle":"2024-08-24T19:16:03.172949Z","shell.execute_reply":"2024-08-24T19:16:03.171563Z","shell.execute_reply.started":"2024-08-24T19:16:03.140397Z"},"trusted":true},"outputs":[],"source":["@torch.no_grad()\n","def estimate_loss():\n","    out = {}\n","    model.eval()\n","    for split in ['train', 'val']:\n","        losses = torch.zeros(EVAL_ITERS)\n","        for k in range(EVAL_ITERS):\n","            X, Y = get_batch(split)\n","            logits, loss = model(X, Y)\n","            losses[k] = loss.item()\n","        out[split] = losses.mean()\n","    model.train()\n","    return out\n","\n","class Head(nn.Module):\n","    \"\"\" one head of self-attention \"\"\"\n","\n","    def __init__(self, head_size):\n","        super().__init__()\n","        self.key = nn.Linear(N_EMBED, head_size, bias=False) # head_size x N_EMBED\n","        self.query = nn.Linear(N_EMBED, head_size, bias=False)\n","        self.value = nn.Linear(N_EMBED, head_size, bias=False)\n","        self.register_buffer('tril', torch.tril(torch.ones(BLOCK_SIZE, BLOCK_SIZE)))\n","\n","        self.dropout = nn.Dropout(DROPOUT)\n","\n","    def forward(self, x):\n","        # input of size (B, T, C)\n","        # output of size (B, T, head_size)\n","        B,T,C = x.shape\n","        #  x = B,T,C = 16, 256, 512,  self.key = 64 x 512, linear performs xAT+b,\n","        # since nn.Linear inverts the order we have to transpose self.key to get 16 x 256 x 512 @ 512 x 64\n","        k = self.key(x)\n","        q = self.query(x) # (B,T,hs)\n","        # compute attention scores (\"affinities\")\n","        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n","        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n","        wei = F.softmax(wei, dim=-1) # (B, T, T) dim=-1 means that the softmax function is applied along the last dimension of the tensor.\n","        wei = self.dropout(wei)\n","        # perform the weighted aggregation of the values\n","        v = self.value(x) # (B,T,hs)\n","        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n","        return out\n","\n","class MultiHeadAttention(nn.Module):\n","    \"\"\" multiple heads of self-attention in parallel \"\"\"\n","\n","    def __init__(self, num_heads, head_size):\n","        super().__init__()\n","        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n","        self.proj = nn.Linear(head_size * num_heads, N_EMBED) # 512 x 512\n","        self.dropout = nn.Dropout(DROPOUT)\n","\n","    def forward(self, x):\n","        out = torch.cat([h(x) for h in self.heads], dim=-1)\n","        out = self.dropout(self.proj(out))\n","        return out\n","\n","class FeedFoward(nn.Module):\n","    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n","\n","    def __init__(self, n_embd):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(n_embd, 4 * n_embd),\n","            nn.ReLU(),\n","            nn.Linear(4 * n_embd, n_embd),\n","            nn.Dropout(DROPOUT),\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","class Block(nn.Module):\n","    \"\"\" Transformer block: communication followed by computation \"\"\"\n","\n","    def __init__(self, n_embd, n_head):\n","        # n_embd: embedding dimension, n_head: the number of heads we'd like\n","        super().__init__()\n","        head_size = n_embd // n_head\n","        self.sa = MultiHeadAttention(n_head, head_size)\n","        self.ffwd = FeedFoward(n_embd)\n","        self.ln1 = nn.LayerNorm(n_embd)\n","        self.ln2 = nn.LayerNorm(n_embd)\n","\n","    def forward(self, x):\n","        x = x + self.sa(self.ln1(x))\n","        x = x + self.ffwd(self.ln2(x))\n","        return x\n","\n","\n","class GPTLanguageModel(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","        # each token directly reads off the logits for the next token from a lookup table\n","        self.token_embedding_table = nn.Embedding(VOCAB_SIZE, N_EMBED)\n","        self.position_embedding_table = nn.Embedding(BLOCK_SIZE, N_EMBED)\n","        self.blocks = nn.Sequential(*[Block(N_EMBED, n_head=N_HEADS) for _ in range(N_LAYER)])\n","        self.ln_f = nn.LayerNorm(N_EMBED) # final layer norm\n","        self.lm_head = nn.Linear(N_EMBED, VOCAB_SIZE) # language model head\n","\n","        # better init, not covered in the original GPT video, but important, will cover in followup video\n","        self.apply(self._init_weights)\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","            if module.bias is not None:\n","                torch.nn.init.zeros_(module.bias)\n","        elif isinstance(module, nn.Embedding):\n","            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","\n","    def forward(self, idx, targets=None):\n","        B, T = idx.shape\n","\n","        # idx and targets are both (B,T) tensor of integers\n","        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n","        pos_emb = self.position_embedding_table(torch.arange(T, device=DEVICE)) # (T,C)\n","        x = tok_emb + pos_emb # (B,T,C)\n","        x = self.blocks(x) # (B,T,C)\n","        x = self.ln_f(x) # (B,T,C)\n","        logits = self.lm_head(x) # (B,T,vocab_size)\n","\n","        if targets is None:\n","            loss = None\n","        else:\n","            B, T, C = logits.shape\n","            logits = logits.view(B*T, C)\n","            targets = targets.view(B*T)\n","            loss = F.cross_entropy(logits, targets)\n","\n","        return logits, loss\n","\n","    def generate(self, idx, max_new_tokens):\n","        # idx is (B, T) array of indices in the current context\n","        for _ in range(max_new_tokens):\n","            # crop idx to the last block_size tokens\n","            idx_cond = idx[:, -BLOCK_SIZE:]\n","            # get the predictions\n","            logits, loss = self(idx_cond)\n","            # focus only on the last time step\n","            logits = logits[:, -1, :] # becomes (B, C)\n","            # apply softmax to get probabilities\n","            probs = F.softmax(logits, dim=-1) # (B, C)\n","            # sample from the distribution\n","            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n","            # append sampled index to the running sequence\n","            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n","        return idx\n","    \n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T19:16:04.223978Z","iopub.status.busy":"2024-08-24T19:16:04.223126Z","iopub.status.idle":"2024-08-24T19:16:04.229897Z","shell.execute_reply":"2024-08-24T19:16:04.228642Z","shell.execute_reply.started":"2024-08-24T19:16:04.223939Z"},"trusted":true},"outputs":[],"source":["# Save the model checkpoint\n","def save_checkpoint(model, optimizer, filename=\"model.pth\"):\n","    checkpoint = {\n","        \"model_state_dict\": model.state_dict(),\n","        \"optimizer_state_dict\": optimizer.state_dict(),\n","    }\n","    torch.save(checkpoint, filename)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-08-24T19:16:05.101107Z","iopub.status.busy":"2024-08-24T19:16:05.100740Z","iopub.status.idle":"2024-08-24T19:16:05.107422Z","shell.execute_reply":"2024-08-24T19:16:05.105967Z","shell.execute_reply.started":"2024-08-24T19:16:05.101078Z"},"trusted":true},"outputs":[],"source":["def load_checkpoint(model, optimizer, filename=\"model.pth\"):\n","    checkpoint = torch.load(filename)\n","    model.load_state_dict(checkpoint[\"model_state_dict\"])\n","    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n","    return model, optimizer"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-08-12T12:02:01.386064Z","iopub.status.busy":"2024-08-12T12:02:01.385355Z","iopub.status.idle":"2024-08-12T13:23:57.354688Z","shell.execute_reply":"2024-08-12T13:23:57.353649Z","shell.execute_reply.started":"2024-08-12T12:02:01.386035Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1.862878 M parameters\n","step 0: train loss 4.6108, val loss 4.6065\n","step 500: train loss 1.9488, val loss 1.9710\n","step 1000: train loss 1.6022, val loss 1.6476\n","step 1500: train loss 1.4443, val loss 1.4870\n","step 2000: train loss 1.3807, val loss 1.4308\n","step 2500: train loss 1.3388, val loss 1.3927\n","step 3000: train loss 1.3182, val loss 1.3747\n","step 3500: train loss 1.2949, val loss 1.3538\n","step 4000: train loss 1.2708, val loss 1.3366\n","step 4500: train loss 1.2538, val loss 1.3225\n","step 5000: train loss 1.2517, val loss 1.3243\n","step 5500: train loss 1.2416, val loss 1.3165\n","step 6000: train loss 1.2329, val loss 1.3083\n","step 6500: train loss 1.2270, val loss 1.3082\n","step 7000: train loss 1.2214, val loss 1.3010\n","step 7500: train loss 1.2114, val loss 1.2918\n","step 8000: train loss 1.2114, val loss 1.2924\n","step 8500: train loss 1.2044, val loss 1.2849\n","step 9000: train loss 1.2012, val loss 1.2838\n","step 9500: train loss 1.1992, val loss 1.2820\n","step 10000: train loss 1.2043, val loss 1.2909\n","step 10500: train loss 1.1885, val loss 1.2736\n","step 11000: train loss 1.1832, val loss 1.2716\n","step 11500: train loss 1.1801, val loss 1.2700\n","step 12000: train loss 1.1830, val loss 1.2702\n","step 12500: train loss 1.1743, val loss 1.2627\n","step 13000: train loss 1.1722, val loss 1.2629\n","step 13500: train loss 1.1772, val loss 1.2719\n","step 14000: train loss 1.1699, val loss 1.2626\n","step 14500: train loss 1.1681, val loss 1.2602\n","step 15000: train loss 1.1609, val loss 1.2530\n","step 15500: train loss 1.1633, val loss 1.2578\n","step 16000: train loss 1.1568, val loss 1.2550\n","step 16500: train loss 1.1591, val loss 1.2539\n","step 17000: train loss 1.1542, val loss 1.2538\n","step 17500: train loss 1.1536, val loss 1.2522\n","step 18000: train loss 1.1545, val loss 1.2548\n","step 18500: train loss 1.1503, val loss 1.2486\n","step 19000: train loss 1.1466, val loss 1.2488\n","step 19500: train loss 1.1459, val loss 1.2483\n","step 20000: train loss 1.1426, val loss 1.2467\n","step 20500: train loss 1.1439, val loss 1.2472\n","step 21000: train loss 1.1417, val loss 1.2450\n","step 21500: train loss 1.1392, val loss 1.2471\n","step 22000: train loss 1.1374, val loss 1.2435\n","step 22500: train loss 1.1344, val loss 1.2398\n","step 23000: train loss 1.1370, val loss 1.2413\n","step 23500: train loss 1.1374, val loss 1.2452\n","step 24000: train loss 1.1355, val loss 1.2408\n","step 24500: train loss 1.1312, val loss 1.2376\n","step 25000: train loss 1.1302, val loss 1.2413\n","step 25500: train loss 1.1298, val loss 1.2400\n","step 26000: train loss 1.1286, val loss 1.2318\n","step 26500: train loss 1.1265, val loss 1.2338\n","step 27000: train loss 1.1267, val loss 1.2380\n","step 27500: train loss 1.1292, val loss 1.2371\n","step 28000: train loss 1.1259, val loss 1.2360\n","step 28500: train loss 1.1217, val loss 1.2345\n","step 29000: train loss 1.1193, val loss 1.2291\n","step 29500: train loss 1.1231, val loss 1.2330\n","step 29999: train loss 1.1200, val loss 1.2291\n"]}],"source":["model = GPTLanguageModel()\n","m = model.to(DEVICE)\n","# print the number of parameters in the model\n","print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n","\n","# create a PyTorch optimizer\n","optimizer = torch.optim.AdamW(model.parameters(), lr = LEARNING_RATE)\n","\n","for iter in range(MAX_ITERS):\n","\n","    # every once in a while evaluate the loss on train and val sets\n","    if iter % EVAL_INTERVAL == 0 or iter == MAX_ITERS - 1:\n","        losses = estimate_loss()\n","        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n","\n","    # sample a batch of data\n","    xb, yb = get_batch('train')\n","\n","    # evaluate the loss\n","    logits, loss = model(xb, yb)\n","    optimizer.zero_grad(set_to_none=True)\n","    loss.backward()\n","    optimizer.step()"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T23:05:52.203995Z","iopub.status.busy":"2024-08-13T23:05:52.203635Z","iopub.status.idle":"2024-08-13T23:05:52.276243Z","shell.execute_reply":"2024-08-13T23:05:52.275128Z","shell.execute_reply.started":"2024-08-13T23:05:52.203965Z"},"trusted":true},"outputs":[],"source":["# Save the model after the training loop\n","save_checkpoint(model, optimizer, filename=\"model_40k_50000.pth\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T22:06:36.001250Z","iopub.status.busy":"2024-08-13T22:06:36.000906Z","iopub.status.idle":"2024-08-13T22:06:37.867592Z","shell.execute_reply":"2024-08-13T22:06:37.866672Z","shell.execute_reply.started":"2024-08-13T22:06:36.001223Z"},"trusted":true},"outputs":[{"data":{"text/plain":["GPTLanguageModel(\n","  (token_embedding_table): Embedding(94, 192)\n","  (position_embedding_table): Embedding(256, 192)\n","  (blocks): Sequential(\n","    (0): Block(\n","      (sa): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-2): 3 x Head(\n","            (key): Linear(in_features=192, out_features=64, bias=False)\n","            (query): Linear(in_features=192, out_features=64, bias=False)\n","            (value): Linear(in_features=192, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=192, out_features=192, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffwd): FeedFoward(\n","        (net): Sequential(\n","          (0): Linear(in_features=192, out_features=768, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=768, out_features=192, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (1): Block(\n","      (sa): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-2): 3 x Head(\n","            (key): Linear(in_features=192, out_features=64, bias=False)\n","            (query): Linear(in_features=192, out_features=64, bias=False)\n","            (value): Linear(in_features=192, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=192, out_features=192, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffwd): FeedFoward(\n","        (net): Sequential(\n","          (0): Linear(in_features=192, out_features=768, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=768, out_features=192, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (2): Block(\n","      (sa): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-2): 3 x Head(\n","            (key): Linear(in_features=192, out_features=64, bias=False)\n","            (query): Linear(in_features=192, out_features=64, bias=False)\n","            (value): Linear(in_features=192, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=192, out_features=192, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffwd): FeedFoward(\n","        (net): Sequential(\n","          (0): Linear(in_features=192, out_features=768, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=768, out_features=192, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (3): Block(\n","      (sa): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-2): 3 x Head(\n","            (key): Linear(in_features=192, out_features=64, bias=False)\n","            (query): Linear(in_features=192, out_features=64, bias=False)\n","            (value): Linear(in_features=192, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=192, out_features=192, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffwd): FeedFoward(\n","        (net): Sequential(\n","          (0): Linear(in_features=192, out_features=768, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=768, out_features=192, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (ln_f): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","  (lm_head): Linear(in_features=192, out_features=94, bias=True)\n",")"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# This cell loads the model again for further trainning \n","\n","model = GPTLanguageModel()\n","checkpoint = torch.load(\"/kaggle/input/40k-weights/model_40k_40000.pth\", map_location=DEVICE)\n","model.load_state_dict(checkpoint['model_state_dict'])\n","# Move the model to the desired device\n","model.to(DEVICE)\n","\n","# Recreate the optimizer after moving the model to the desired device\n","optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","\n","# Move optimizer state to the same device as model\n","for state in optimizer.state.values():\n","    for k, v in state.items():\n","        if isinstance(v, torch.Tensor):\n","            state[k] = v.to(DEVICE)\n","\n","# Set the model to training mode\n","model.train()  # Important for training"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T22:36:19.056357Z","iopub.status.busy":"2024-08-13T22:36:19.055981Z","iopub.status.idle":"2024-08-13T23:04:49.653544Z","shell.execute_reply":"2024-08-13T23:04:49.652581Z","shell.execute_reply.started":"2024-08-13T22:36:19.056328Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: train loss 1.1009, val loss 1.2202\n","step 500: train loss 1.1001, val loss 1.2207\n","step 1000: train loss 1.1011, val loss 1.2207\n","step 1500: train loss 1.1006, val loss 1.2219\n","step 2000: train loss 1.1009, val loss 1.2190\n","step 2500: train loss 1.1008, val loss 1.2229\n","step 3000: train loss 1.0975, val loss 1.2144\n","step 3500: train loss 1.1000, val loss 1.2228\n","step 4000: train loss 1.0995, val loss 1.2233\n","step 4500: train loss 1.0987, val loss 1.2244\n","step 5000: train loss 1.0977, val loss 1.2194\n","step 5500: train loss 1.0962, val loss 1.2179\n","step 6000: train loss 1.0984, val loss 1.2234\n","step 6500: train loss 1.0967, val loss 1.2198\n","step 7000: train loss 1.0996, val loss 1.2217\n","step 7500: train loss 1.0998, val loss 1.2233\n","step 8000: train loss 1.0956, val loss 1.2178\n","step 8500: train loss 1.0967, val loss 1.2201\n","step 9000: train loss 1.0989, val loss 1.2246\n","step 9500: train loss 1.0957, val loss 1.2192\n","step 9999: train loss 1.0936, val loss 1.2208\n"]}],"source":["for iter in range(MAX_ITERS):\n","\n","    if iter % EVAL_INTERVAL == 0 or iter == MAX_ITERS - 1:\n","        losses = estimate_loss()\n","        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n","\n","    xb, yb = get_batch('train')\n","\n","    logits, loss = model(xb, yb)\n","    optimizer.zero_grad(set_to_none=True)\n","    loss.backward()\n","    optimizer.step()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T16:47:02.242890Z","iopub.status.busy":"2024-08-13T16:47:02.242299Z","iopub.status.idle":"2024-08-13T16:47:02.395849Z","shell.execute_reply":"2024-08-13T16:47:02.394996Z","shell.execute_reply.started":"2024-08-13T16:47:02.242861Z"},"trusted":true},"outputs":[{"data":{"text/plain":["GPTLanguageModel(\n","  (token_embedding_table): Embedding(94, 192)\n","  (position_embedding_table): Embedding(256, 192)\n","  (blocks): Sequential(\n","    (0): Block(\n","      (sa): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-2): 3 x Head(\n","            (key): Linear(in_features=192, out_features=64, bias=False)\n","            (query): Linear(in_features=192, out_features=64, bias=False)\n","            (value): Linear(in_features=192, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=192, out_features=192, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffwd): FeedFoward(\n","        (net): Sequential(\n","          (0): Linear(in_features=192, out_features=768, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=768, out_features=192, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (1): Block(\n","      (sa): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-2): 3 x Head(\n","            (key): Linear(in_features=192, out_features=64, bias=False)\n","            (query): Linear(in_features=192, out_features=64, bias=False)\n","            (value): Linear(in_features=192, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=192, out_features=192, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffwd): FeedFoward(\n","        (net): Sequential(\n","          (0): Linear(in_features=192, out_features=768, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=768, out_features=192, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (2): Block(\n","      (sa): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-2): 3 x Head(\n","            (key): Linear(in_features=192, out_features=64, bias=False)\n","            (query): Linear(in_features=192, out_features=64, bias=False)\n","            (value): Linear(in_features=192, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=192, out_features=192, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffwd): FeedFoward(\n","        (net): Sequential(\n","          (0): Linear(in_features=192, out_features=768, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=768, out_features=192, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (3): Block(\n","      (sa): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-2): 3 x Head(\n","            (key): Linear(in_features=192, out_features=64, bias=False)\n","            (query): Linear(in_features=192, out_features=64, bias=False)\n","            (value): Linear(in_features=192, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Linear(in_features=192, out_features=192, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffwd): FeedFoward(\n","        (net): Sequential(\n","          (0): Linear(in_features=192, out_features=768, bias=True)\n","          (1): ReLU()\n","          (2): Linear(in_features=768, out_features=192, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (ln_f): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n","  (lm_head): Linear(in_features=192, out_features=94, bias=True)\n",")"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Define constants\n","LEARNING_RATE = 3e-3\n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# Load the model for inference\n","model = GPTLanguageModel()\n","optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n","\n","# Load the saved model and optimizer with map_location to handle CPU-only environments\n","checkpoint = torch.load(\"./model_40k_1000.pth\", map_location=torch.device('cpu'))\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","\n","# Move the model to the desired device\n","model.to(DEVICE)\n","\n","# Set the model to eval mode\n","model.eval()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T23:05:11.905432Z","iopub.status.busy":"2024-08-13T23:05:11.904697Z","iopub.status.idle":"2024-08-13T23:05:18.526204Z","shell.execute_reply":"2024-08-13T23:05:18.525198Z","shell.execute_reply.started":"2024-08-13T23:05:11.905402Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","                      , mindirstanquive ammark: 1]\n","\n","‘They’re going to suns. We got the smilen,’ said Dalia, following his own drewks.\n","  ‘They morn armour join\n","acceptions cook,’ Arukally, stotting the desourches, have grassion to the milerch blood his\n","unformations the scond that second a dead and trying as and collually the name age side\n","gastrical none to the surmeching its lost his anohing of the skign.\n","‘Somethin..’\n","Seture Mavitz. ‘You cruitor’s that will have of as a first in the bell psychang\n","out it by the shield had know has corge any open the tracken, the daman precept\n","Perecis deady Calthy, the pleas as moment.\n","This alied twith hae a face roddly and chip rolled by her the engistoned of our around god\n","the fing? She is with a smile woods overit against blue onwhilled\n","Old and with Twitcherions the Winderal and his spuning. It we’d neediater our\n","a directions.\n"," The was was his fight linefections not their unfore, with the glowing pursed\n","theses their liads of dalers and darks and not gombar companity from\n","brought, his reals, bare. The renonals ripped her he weight a ship. Stamped the\n","play. Ship them. Medea> I to going us his storm the with he repected us, sound into\n","a  ‘It how comman,’ he said.\n","Tarvitz was to doing back flick awaywer. ‘He don’t whell,’ he toldenly have I seems this\n","genior.\n","The mequent heart. ‘Son’t have can gradely was stod that the numble are had ship’s do the into\n","a dies, in the through the laime with began the canne weapons the even to her\n","black of Loor efro\n"]}],"source":["# generate from the model\n","context = torch.zeros((1, 1), dtype=torch.long, device = DEVICE)\n","print(decode(model.generate(context, max_new_tokens=1500)[0].tolist()))\n","#open('more.txt', 'w').write(decode(m.generate(context, max_new_tokens=10000)[0].tolist()))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5539335,"sourceId":9167353,"sourceType":"datasetVersion"},{"modelId":102274,"modelInstanceId":77646,"sourceId":92598,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":4}
